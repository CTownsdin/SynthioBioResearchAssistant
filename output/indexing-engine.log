2025-09-08 14:30:06.0281 - ERROR - graphrag.language_model.providers.fnllm.utils - Error Invoking LLM
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 30000, Used 30000, Requested 15. Please try again in 30ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:30:06.0284 - ERROR - graphrag.index.validate_config - LLM configuration error detected. Exiting...
Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 30000, Used 30000, Requested 15. Please try again in 30ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:39:39.0754 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-09-08 14:39:40.0138 - INFO - graphrag.index.validate_config - Embedding LLM Config Params Validated
2025-09-08 14:39:40.0139 - INFO - graphrag.cli.index - Starting pipeline run. False
2025-09-08 14:39:40.0140 - INFO - graphrag.cli.index - Using default configuration: {
    "root_dir": "/Users/ctown/src/ResearchAssistantHackathon",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4.1-nano",
            "encoding_model": "o200k_base",
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "request_timeout": 180.0,
            "tokens_per_minute": "auto",
            "requests_per_minute": "auto",
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "storage": {
            "type": "file",
            "base_dir": "/Users/ctown/src/ResearchAssistantHackathon/input",
            "storage_account_blob_url": null,
            "cosmosdb_account_url": null
        },
        "file_type": "text",
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/ctown/src/ResearchAssistantHackathon/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/ctown/src/ResearchAssistantHackathon/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/ctown/src/ResearchAssistantHackathon/output",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/ctown/src/ResearchAssistantHackathon/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "names": [
            "entity.description",
            "community.full_content",
            "text_unit.text"
        ],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event",
            "gene",
            "mutation",
            "drug",
            "cell_type",
            "assay",
            "disease",
            "protein"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 300,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 1500,
        "max_input_length": 4000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": true,
        "dimensions": 128,
        "num_walks": 20,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": true
    },
    "snapshots": {
        "embeddings": true,
        "graphml": true,
        "raw_graph": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
2025-09-08 14:39:40.0141 - INFO - graphrag.api.index - Initializing indexing pipeline...
2025-09-08 14:39:40.0141 - INFO - graphrag.index.workflows.factory - Creating pipeline with workflows: ['load_input_documents', 'create_base_text_units', 'create_final_documents', 'extract_graph_nlp', 'prune_graph', 'finalize_graph', 'create_communities', 'create_final_text_units', 'create_community_reports_text', 'generate_text_embeddings']
2025-09-08 14:39:40.0141 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /Users/ctown/src/ResearchAssistantHackathon/input
2025-09-08 14:39:40.0141 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /Users/ctown/src/ResearchAssistantHackathon/output
2025-09-08 14:39:40.0142 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /Users/ctown/src/ResearchAssistantHackathon
2025-09-08 14:39:40.0142 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /Users/ctown/src/ResearchAssistantHackathon/cache
2025-09-08 14:39:40.0143 - INFO - graphrag.index.run.run_pipeline - Running standard indexing.
2025-09-08 14:39:40.0143 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at 
2025-09-08 14:39:40.0144 - INFO - graphrag.index.run.run_pipeline - Executing pipeline...
2025-09-08 14:39:40.0144 - INFO - graphrag.index.input.factory - loading input from root_dir=/Users/ctown/src/ResearchAssistantHackathon/input
2025-09-08 14:39:40.0144 - INFO - graphrag.index.input.factory - Loading Input InputFileType.text
2025-09-08 14:39:40.0145 - INFO - graphrag.storage.file_pipeline_storage - search /Users/ctown/src/ResearchAssistantHackathon/input for files matching .*\.txt$
2025-09-08 14:39:40.0145 - DEBUG - graphrag.storage.file_pipeline_storage - Files loaded: 1, filtered: 0, total: 7
2025-09-08 14:39:40.0145 - DEBUG - graphrag.storage.file_pipeline_storage - Files loaded: 2, filtered: 0, total: 7
2025-09-08 14:39:40.0145 - DEBUG - graphrag.storage.file_pipeline_storage - Files loaded: 3, filtered: 0, total: 7
2025-09-08 14:39:40.0145 - DEBUG - graphrag.storage.file_pipeline_storage - Files loaded: 4, filtered: 0, total: 7
2025-09-08 14:39:40.0145 - DEBUG - graphrag.storage.file_pipeline_storage - Files loaded: 5, filtered: 0, total: 7
2025-09-08 14:39:40.0145 - DEBUG - graphrag.storage.file_pipeline_storage - Files loaded: 6, filtered: 0, total: 7
2025-09-08 14:39:40.0145 - DEBUG - graphrag.storage.file_pipeline_storage - Files loaded: 7, filtered: 0, total: 7
2025-09-08 14:39:40.0156 - INFO - graphrag.index.input.util - Found 7 InputFileType.text files, loading 7
2025-09-08 14:39:40.0157 - INFO - graphrag.index.input.util - Total number of unfiltered InputFileType.text rows: 7
2025-09-08 14:39:40.0157 - INFO - graphrag.index.workflows.load_input_documents - Final # of rows loaded: 7
2025-09-08 14:39:40.0187 - INFO - graphrag.api.index - Workflow load_input_documents completed successfully
2025-09-08 14:39:40.0190 - DEBUG - graphrag.api.index -                                                 text  ...              creation_date
0  Title: Discovery of N-(3-Carbamoyl-5,5,7,7-tet...  ...  2025-09-08 13:56:14 -0700
0  Title: Measuring the Infectious Titer of Recom...  ...  2025-09-08 13:56:14 -0700
0  Title: Prime editing for precise and highly ve...  ...  2025-09-08 13:56:14 -0700
0  Title: Generation of two induced pluripotent s...  ...  2025-09-08 13:56:14 -0700
0  Title: The delta F508 mutation decreases the s...  ...  2025-09-08 13:56:14 -0700
0  Title: CFTR genotype analysis of Asians in int...  ...  2025-09-08 13:56:14 -0700
0  Title: Protocol for application, standardizati...  ...  2025-09-08 13:56:14 -0700

[7 rows x 4 columns]
2025-09-08 14:39:40.0190 - INFO - graphrag.index.workflows.create_base_text_units - Workflow started: create_base_text_units
2025-09-08 14:39:40.0190 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-09-08 14:39:40.0210 - INFO - graphrag.index.workflows.create_base_text_units - Starting chunking process for 7 documents
2025-09-08 14:39:40.0217 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1/7
2025-09-08 14:39:40.0230 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  2/7
2025-09-08 14:39:40.0238 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  3/7
2025-09-08 14:39:40.0239 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  4/7
2025-09-08 14:39:40.0243 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  5/7
2025-09-08 14:39:40.0253 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  6/7
2025-09-08 14:39:40.0258 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  7/7
2025-09-08 14:39:40.0268 - INFO - graphrag.index.workflows.create_base_text_units - Workflow completed: create_base_text_units
2025-09-08 14:39:40.0270 - INFO - graphrag.api.index - Workflow create_base_text_units completed successfully
2025-09-08 14:39:40.0272 - DEBUG - graphrag.api.index -                                                    id  ... n_tokens
0   accdca769e88d29b429be3731b96c5ceb2795667056e0f...  ...     1200
1   bac7edde4473bb43330d983443c67f1a0c8c971b98470c...  ...     1200
2   32bd73456930453483b1c170bf555ca0c614f897d8530e...  ...     1200
3   cd7bf186a6dc62a0d87691b33552ebf17f2b95f7a54978...  ...     1200
4   eb7c98c0364901d44179d7cf8b255eeb20293200492db8...  ...     1200
..                                                ...  ...      ...
78  cb96beb68969042181d1fc56d869f58251e2cf28667c9a...  ...     1200
79  857a7c9650ab3ab8c047946be4c4d17f4f89e696695997...  ...     1200
80  755ba681405a00b8d303b285b82b5b25d3a53433e81659...  ...     1200
81  16e9b2af109874514097d23633a85a3fbea2514b7b1257...  ...     1200
82  296a2e3f40ece005fad567573f5e46631e26c1a0d657dc...  ...      618

[83 rows x 4 columns]
2025-09-08 14:39:40.0272 - INFO - graphrag.index.workflows.create_final_documents - Workflow started: create_final_documents
2025-09-08 14:39:40.0272 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-09-08 14:39:40.0274 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-09-08 14:39:40.0283 - INFO - graphrag.index.workflows.create_final_documents - Workflow completed: create_final_documents
2025-09-08 14:39:40.0286 - INFO - graphrag.api.index - Workflow create_final_documents completed successfully
2025-09-08 14:39:40.0288 - DEBUG - graphrag.api.index -                                                   id  human_readable_id  ...              creation_date metadata
0  92752026a148b22773014f0f94be1a89d2a50a2e13f44c...                  0  ...  2025-09-08 13:56:14 -0700      NaN
1  8452fa0eb18e8114eaad5f56909baf777cf997ea97fe1c...                  1  ...  2025-09-08 13:56:14 -0700      NaN
2  693874e7039d0c5f9f86a9f8042de58a048e653ac4dd83...                  2  ...  2025-09-08 13:56:14 -0700      NaN
3  27d7bf2ad3d8a0483aa944216090f1950075f73c70e188...                  3  ...  2025-09-08 13:56:14 -0700      NaN
4  53dce85706c2c6d897ec982f694840d78339e00f5b9c12...                  4  ...  2025-09-08 13:56:14 -0700      NaN
5  4c1edcdf10330f4a7774fe7d72e2c4ddf52bf27f0d63be...                  5  ...  2025-09-08 13:56:14 -0700      NaN
6  d2c3b2a3f53de1a690e8e90245bb0507f785c5465c3189...                  6  ...  2025-09-08 13:56:14 -0700      NaN

[7 rows x 7 columns]
2025-09-08 14:39:40.0288 - INFO - graphrag.index.workflows.extract_graph_nlp - Workflow started: extract_graph_nlp
2025-09-08 14:39:40.0288 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-09-08 14:39:40.0294 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /Users/ctown/src/ResearchAssistantHackathon/cache/extract_noun_phrases
2025-09-08 14:39:42.0037 - INFO - graphrag.logger.progress - extract noun phrases progress: 1/83
2025-09-08 14:39:42.0038 - INFO - graphrag.logger.progress - extract noun phrases progress: 2/83
2025-09-08 14:39:42.0038 - INFO - graphrag.logger.progress - extract noun phrases progress: 3/83
2025-09-08 14:39:42.0038 - INFO - graphrag.logger.progress - extract noun phrases progress: 4/83
2025-09-08 14:39:42.0038 - INFO - graphrag.logger.progress - extract noun phrases progress: 5/83
2025-09-08 14:39:42.0038 - INFO - graphrag.logger.progress - extract noun phrases progress: 6/83
2025-09-08 14:39:42.0038 - INFO - graphrag.logger.progress - extract noun phrases progress: 7/83
2025-09-08 14:39:42.0038 - INFO - graphrag.logger.progress - extract noun phrases progress: 8/83
2025-09-08 14:39:42.0038 - INFO - graphrag.logger.progress - extract noun phrases progress: 9/83
2025-09-08 14:39:42.0038 - INFO - graphrag.logger.progress - extract noun phrases progress: 10/83
2025-09-08 14:39:42.0038 - INFO - graphrag.logger.progress - extract noun phrases progress: 11/83
2025-09-08 14:39:42.0038 - INFO - graphrag.logger.progress - extract noun phrases progress: 12/83
2025-09-08 14:39:42.0038 - INFO - graphrag.logger.progress - extract noun phrases progress: 13/83
2025-09-08 14:39:42.0038 - INFO - graphrag.logger.progress - extract noun phrases progress: 14/83
2025-09-08 14:39:42.0038 - INFO - graphrag.logger.progress - extract noun phrases progress: 15/83
2025-09-08 14:39:42.0039 - INFO - graphrag.logger.progress - extract noun phrases progress: 16/83
2025-09-08 14:39:42.0039 - INFO - graphrag.logger.progress - extract noun phrases progress: 17/83
2025-09-08 14:39:42.0039 - INFO - graphrag.logger.progress - extract noun phrases progress: 18/83
2025-09-08 14:39:42.0039 - INFO - graphrag.logger.progress - extract noun phrases progress: 19/83
2025-09-08 14:39:42.0039 - INFO - graphrag.logger.progress - extract noun phrases progress: 20/83
2025-09-08 14:39:42.0039 - INFO - graphrag.logger.progress - extract noun phrases progress: 21/83
2025-09-08 14:39:42.0039 - INFO - graphrag.logger.progress - extract noun phrases progress: 22/83
2025-09-08 14:39:42.0039 - INFO - graphrag.logger.progress - extract noun phrases progress: 23/83
2025-09-08 14:39:42.0039 - INFO - graphrag.logger.progress - extract noun phrases progress: 24/83
2025-09-08 14:39:42.0039 - INFO - graphrag.logger.progress - extract noun phrases progress: 25/83
2025-09-08 14:39:42.0620 - INFO - graphrag.logger.progress - extract noun phrases progress: 26/83
2025-09-08 14:39:42.0620 - INFO - graphrag.logger.progress - extract noun phrases progress: 27/83
2025-09-08 14:39:42.0620 - INFO - graphrag.logger.progress - extract noun phrases progress: 28/83
2025-09-08 14:39:42.0620 - INFO - graphrag.logger.progress - extract noun phrases progress: 29/83
2025-09-08 14:39:42.0620 - INFO - graphrag.logger.progress - extract noun phrases progress: 30/83
2025-09-08 14:39:42.0620 - INFO - graphrag.logger.progress - extract noun phrases progress: 31/83
2025-09-08 14:39:42.0621 - INFO - graphrag.logger.progress - extract noun phrases progress: 32/83
2025-09-08 14:39:42.0621 - INFO - graphrag.logger.progress - extract noun phrases progress: 33/83
2025-09-08 14:39:42.0621 - INFO - graphrag.logger.progress - extract noun phrases progress: 34/83
2025-09-08 14:39:42.0621 - INFO - graphrag.logger.progress - extract noun phrases progress: 35/83
2025-09-08 14:39:42.0621 - INFO - graphrag.logger.progress - extract noun phrases progress: 36/83
2025-09-08 14:39:42.0621 - INFO - graphrag.logger.progress - extract noun phrases progress: 37/83
2025-09-08 14:39:42.0621 - INFO - graphrag.logger.progress - extract noun phrases progress: 38/83
2025-09-08 14:39:42.0621 - INFO - graphrag.logger.progress - extract noun phrases progress: 39/83
2025-09-08 14:39:42.0621 - INFO - graphrag.logger.progress - extract noun phrases progress: 40/83
2025-09-08 14:39:42.0621 - INFO - graphrag.logger.progress - extract noun phrases progress: 41/83
2025-09-08 14:39:42.0621 - INFO - graphrag.logger.progress - extract noun phrases progress: 42/83
2025-09-08 14:39:42.0621 - INFO - graphrag.logger.progress - extract noun phrases progress: 43/83
2025-09-08 14:39:42.0621 - INFO - graphrag.logger.progress - extract noun phrases progress: 44/83
2025-09-08 14:39:42.0622 - INFO - graphrag.logger.progress - extract noun phrases progress: 45/83
2025-09-08 14:39:42.0622 - INFO - graphrag.logger.progress - extract noun phrases progress: 46/83
2025-09-08 14:39:42.0622 - INFO - graphrag.logger.progress - extract noun phrases progress: 47/83
2025-09-08 14:39:42.0622 - INFO - graphrag.logger.progress - extract noun phrases progress: 48/83
2025-09-08 14:39:42.0622 - INFO - graphrag.logger.progress - extract noun phrases progress: 49/83
2025-09-08 14:39:42.0677 - INFO - graphrag.logger.progress - extract noun phrases progress: 50/83
2025-09-08 14:39:43.0245 - INFO - graphrag.logger.progress - extract noun phrases progress: 51/83
2025-09-08 14:39:43.0245 - INFO - graphrag.logger.progress - extract noun phrases progress: 52/83
2025-09-08 14:39:43.0245 - INFO - graphrag.logger.progress - extract noun phrases progress: 53/83
2025-09-08 14:39:43.0246 - INFO - graphrag.logger.progress - extract noun phrases progress: 54/83
2025-09-08 14:39:43.0246 - INFO - graphrag.logger.progress - extract noun phrases progress: 55/83
2025-09-08 14:39:43.0246 - INFO - graphrag.logger.progress - extract noun phrases progress: 56/83
2025-09-08 14:39:43.0246 - INFO - graphrag.logger.progress - extract noun phrases progress: 57/83
2025-09-08 14:39:43.0246 - INFO - graphrag.logger.progress - extract noun phrases progress: 58/83
2025-09-08 14:39:43.0246 - INFO - graphrag.logger.progress - extract noun phrases progress: 59/83
2025-09-08 14:39:43.0247 - INFO - graphrag.logger.progress - extract noun phrases progress: 60/83
2025-09-08 14:39:43.0247 - INFO - graphrag.logger.progress - extract noun phrases progress: 61/83
2025-09-08 14:39:43.0247 - INFO - graphrag.logger.progress - extract noun phrases progress: 62/83
2025-09-08 14:39:43.0247 - INFO - graphrag.logger.progress - extract noun phrases progress: 63/83
2025-09-08 14:39:43.0247 - INFO - graphrag.logger.progress - extract noun phrases progress: 64/83
2025-09-08 14:39:43.0247 - INFO - graphrag.logger.progress - extract noun phrases progress: 65/83
2025-09-08 14:39:43.0247 - INFO - graphrag.logger.progress - extract noun phrases progress: 66/83
2025-09-08 14:39:43.0247 - INFO - graphrag.logger.progress - extract noun phrases progress: 67/83
2025-09-08 14:39:43.0247 - INFO - graphrag.logger.progress - extract noun phrases progress: 68/83
2025-09-08 14:39:43.0247 - INFO - graphrag.logger.progress - extract noun phrases progress: 69/83
2025-09-08 14:39:43.0297 - INFO - graphrag.logger.progress - extract noun phrases progress: 70/83
2025-09-08 14:39:43.0323 - INFO - graphrag.logger.progress - extract noun phrases progress: 71/83
2025-09-08 14:39:43.0323 - INFO - graphrag.logger.progress - extract noun phrases progress: 72/83
2025-09-08 14:39:43.0323 - INFO - graphrag.logger.progress - extract noun phrases progress: 73/83
2025-09-08 14:39:43.0323 - INFO - graphrag.logger.progress - extract noun phrases progress: 74/83
2025-09-08 14:39:43.0375 - INFO - graphrag.logger.progress - extract noun phrases progress: 75/83
2025-09-08 14:39:43.0433 - INFO - graphrag.logger.progress - extract noun phrases progress: 76/83
2025-09-08 14:39:43.0433 - INFO - graphrag.logger.progress - extract noun phrases progress: 77/83
2025-09-08 14:39:43.0433 - INFO - graphrag.logger.progress - extract noun phrases progress: 78/83
2025-09-08 14:39:43.0433 - INFO - graphrag.logger.progress - extract noun phrases progress: 79/83
2025-09-08 14:39:43.0433 - INFO - graphrag.logger.progress - extract noun phrases progress: 80/83
2025-09-08 14:39:43.0433 - INFO - graphrag.logger.progress - extract noun phrases progress: 81/83
2025-09-08 14:39:43.0433 - INFO - graphrag.logger.progress - extract noun phrases progress: 82/83
2025-09-08 14:39:43.0433 - INFO - graphrag.logger.progress - extract noun phrases progress: 83/83
2025-09-08 14:39:45.0716 - INFO - graphrag.index.workflows.extract_graph_nlp - Workflow completed: extract_graph_nlp
2025-09-08 14:39:45.0721 - INFO - graphrag.api.index - Workflow extract_graph_nlp completed successfully
2025-09-08 14:39:45.0726 - DEBUG - graphrag.api.index - {'entities':                               title  frequency                                      text_unit_ids         type description
0                 -F508DEL MUTATION          2  [f067a88e6e98917c94d595bc143c6e187d27f5ba32658...  NOUN PHRASE            
1                   -F508DEL REPAIR          2  [f067a88e6e98917c94d595bc143c6e187d27f5ba32658...  NOUN PHRASE            
2     -MOUSE HORSERADISH PEROXIDASE          1  [bd91391c5a2a36929de4cc337e83b5f21f7205f832747...  NOUN PHRASE            
3                 -MUTANT ORGANOIDS          2  [a58a1a7e40da8dcd01c1d4b118a621e481a4efd6ceb02...  NOUN PHRASE            
4                   -R249S MUTATION          1  [5e35d8dc6e85396d47f6c4a64340448d31fc26c887674...  NOUN PHRASE            
...                             ...        ...                                                ...          ...         ...
4145      ZEOCIN SELECTION CASSETTE          1  [ad411e7106ac647e2d78159115da5eca1e10ebfe6adfe...  NOUN PHRASE            
4146                           ZO-1          2  [db25540a2ea62e2ccd69eeaeee76389b8463b5b42dc1d...  NOUN PHRASE            
4147                            ZUO          1  [a58a1a7e40da8dcd01c1d4b118a621e481a4efd6ceb02...  NOUN PHRASE            
4148                           ZYMO          1  [7c21fe2067855ae442b5970771ca919ccc2016ae3f4af...  NOUN PHRASE            
4149    ZYMOGEN QUICK-DNA MICROPREP          1  [755ba681405a00b8d303b285b82b5b25d3a53433e8165...  NOUN PHRASE            

[4150 rows x 5 columns], 'relationships':                    source                        target    weight                                      text_unit_ids description
0       -F508DEL MUTATION               -F508DEL REPAIR  0.000040  [5b0d1501031ae4d0031feabcc914f69d10f000429adea...            
1       -F508DEL MUTATION                           ABE  0.000013  [5b0d1501031ae4d0031feabcc914f69d10f000429adea...            
2       -F508DEL MUTATION  ADDITIONAL EDITABLE RESIDUES  0.000040  [5b0d1501031ae4d0031feabcc914f69d10f000429adea...            
3       -F508DEL MUTATION                       ADENINE  0.000015  [f067a88e6e98917c94d595bc143c6e187d27f5ba32658...            
4       -F508DEL MUTATION          ADENINE BASE EDITING  0.000034  [5b0d1501031ae4d0031feabcc914f69d10f000429adea...            
...                   ...                           ...       ...                                                ...         ...
281994              ZEISS                  ZEISS LSM800  0.000017  [16e9b2af109874514097d23633a85a3fbea2514b7b125...            
281995              ZEISS                     ZEN IMAGE  0.000020  [16e9b2af109874514097d23633a85a3fbea2514b7b125...            
281996          ZEISS LSM                           ZEN  0.000023  [c6ab95759794d5e25e317ca9c55c377ab4db07eea5050...            
281997       ZEISS LSM800                     ZEN IMAGE  0.000020  [16e9b2af109874514097d23633a85a3fbea2514b7b125...            
281998       ZEISS LSM800   ZYMOGEN QUICK-DNA MICROPREP  0.000020  [755ba681405a00b8d303b285b82b5b25d3a53433e8165...            

[281999 rows x 5 columns]}
2025-09-08 14:39:45.0726 - INFO - graphrag.index.workflows.prune_graph - Workflow started: prune_graph
2025-09-08 14:39:45.0726 - INFO - graphrag.utils.storage - reading table from storage: entities.parquet
2025-09-08 14:39:45.0729 - INFO - graphrag.utils.storage - reading table from storage: relationships.parquet
2025-09-08 14:39:46.0436 - INFO - graphrag.index.workflows.prune_graph - Workflow completed: prune_graph
2025-09-08 14:39:46.0451 - INFO - graphrag.api.index - Workflow prune_graph completed successfully
2025-09-08 14:39:46.0455 - DEBUG - graphrag.api.index - {'entities':                              title  frequency                                      text_unit_ids         type description
0                -F508DEL MUTATION          2  [f067a88e6e98917c94d595bc143c6e187d27f5ba32658...  NOUN PHRASE            
1                  -F508DEL REPAIR          2  [f067a88e6e98917c94d595bc143c6e187d27f5ba32658...  NOUN PHRASE            
2                              ABE          5  [dba5910ed3bf5b79c6d11bd04b04e43a3e14c3ce879e4...  NOUN PHRASE            
3     ADDITIONAL EDITABLE RESIDUES          2  [f067a88e6e98917c94d595bc143c6e187d27f5ba32658...  NOUN PHRASE            
4                          ADENINE          3  [4c6cd6cec114b3448185e8a3c8cfd54598cb4eb3a5ed7...  NOUN PHRASE            
...                            ...        ...                                                ...          ...         ...
1144            SIGNATURE ANALYSIS          2  [cb96beb68969042181d1fc56d869f58251e2cf28667c9...  NOUN PHRASE            
1145          DIFFERENT STRATEGIES          3  [7c7f8c23ff390c5988bced340206ebbd3f97f54406ba7...  NOUN PHRASE            
1146               INITIAL STUDIES          2  [825a72a67aec516a82e128243373e50a9a3534c2a5a14...  NOUN PHRASE            
1147     TRANSLATIONAL READTHROUGH          2  [7c7f8c23ff390c5988bced340206ebbd3f97f54406ba7...  NOUN PHRASE            
1148                       II CFTR          2  [67d27afee6109f8231b523b1e537280fe08ce4a573f17...  NOUN PHRASE            

[1149 rows x 5 columns], 'relationships':                      source                        target    weight                                      text_unit_ids description
0         -F508DEL MUTATION               -F508DEL REPAIR  0.000040  [5b0d1501031ae4d0031feabcc914f69d10f000429adea...            
1         -F508DEL MUTATION                           ABE  0.000013  [5b0d1501031ae4d0031feabcc914f69d10f000429adea...            
2         -F508DEL MUTATION  ADDITIONAL EDITABLE RESIDUES  0.000040  [5b0d1501031ae4d0031feabcc914f69d10f000429adea...            
3         -F508DEL MUTATION                       ADENINE  0.000015  [f067a88e6e98917c94d595bc143c6e187d27f5ba32658...            
4         -F508DEL MUTATION          ADENINE BASE EDITING  0.000034  [5b0d1501031ae4d0031feabcc914f69d10f000429adea...            
...                     ...                           ...       ...                                                ...         ...
45038       INITIAL STUDIES                        SCHENE  0.000017  [825a72a67aec516a82e128243373e50a9a3534c2a5a14...            
45039                SCHENE            SIGNATURE ANALYSIS  0.000017  [cb96beb68969042181d1fc56d869f58251e2cf28667c9...            
45040  DIFFERENT STRATEGIES                       II CFTR  0.000015  [1a57a8f3ba5d7f6a610e53f5dd18cce2a31bd554bc763...            
45041  DIFFERENT STRATEGIES     TRANSLATIONAL READTHROUGH  0.000015  [7c7f8c23ff390c5988bced340206ebbd3f97f54406ba7...            
45042               II CFTR               INITIAL STUDIES  0.000017  [67d27afee6109f8231b523b1e537280fe08ce4a573f17...            

[45043 rows x 5 columns]}
2025-09-08 14:39:46.0455 - INFO - graphrag.index.workflows.finalize_graph - Workflow started: finalize_graph
2025-09-08 14:39:46.0456 - INFO - graphrag.utils.storage - reading table from storage: entities.parquet
2025-09-08 14:39:46.0458 - INFO - graphrag.utils.storage - reading table from storage: relationships.parquet
2025-09-08 14:40:03.0201 - INFO - graphrag.index.workflows.finalize_graph - Workflow completed: finalize_graph
2025-09-08 14:40:03.0208 - INFO - graphrag.api.index - Workflow finalize_graph completed successfully
2025-09-08 14:40:03.0214 - DEBUG - graphrag.api.index - {'entities':                              title  frequency                                      text_unit_ids         type description
0                -F508DEL MUTATION          2  [f067a88e6e98917c94d595bc143c6e187d27f5ba32658...  NOUN PHRASE            
1                  -F508DEL REPAIR          2  [f067a88e6e98917c94d595bc143c6e187d27f5ba32658...  NOUN PHRASE            
2                              ABE          5  [dba5910ed3bf5b79c6d11bd04b04e43a3e14c3ce879e4...  NOUN PHRASE            
3     ADDITIONAL EDITABLE RESIDUES          2  [f067a88e6e98917c94d595bc143c6e187d27f5ba32658...  NOUN PHRASE            
4                          ADENINE          3  [4c6cd6cec114b3448185e8a3c8cfd54598cb4eb3a5ed7...  NOUN PHRASE            
...                            ...        ...                                                ...          ...         ...
1144            SIGNATURE ANALYSIS          2  [cb96beb68969042181d1fc56d869f58251e2cf28667c9...  NOUN PHRASE            
1145          DIFFERENT STRATEGIES          3  [7c7f8c23ff390c5988bced340206ebbd3f97f54406ba7...  NOUN PHRASE            
1146               INITIAL STUDIES          2  [825a72a67aec516a82e128243373e50a9a3534c2a5a14...  NOUN PHRASE            
1147     TRANSLATIONAL READTHROUGH          2  [7c7f8c23ff390c5988bced340206ebbd3f97f54406ba7...  NOUN PHRASE            
1148                       II CFTR          2  [67d27afee6109f8231b523b1e537280fe08ce4a573f17...  NOUN PHRASE            

[1149 rows x 5 columns], 'relationships':                      source                        target    weight                                      text_unit_ids description
0         -F508DEL MUTATION               -F508DEL REPAIR  0.000040  [5b0d1501031ae4d0031feabcc914f69d10f000429adea...            
1         -F508DEL MUTATION                           ABE  0.000013  [5b0d1501031ae4d0031feabcc914f69d10f000429adea...            
2         -F508DEL MUTATION  ADDITIONAL EDITABLE RESIDUES  0.000040  [5b0d1501031ae4d0031feabcc914f69d10f000429adea...            
3         -F508DEL MUTATION                       ADENINE  0.000015  [f067a88e6e98917c94d595bc143c6e187d27f5ba32658...            
4         -F508DEL MUTATION          ADENINE BASE EDITING  0.000034  [5b0d1501031ae4d0031feabcc914f69d10f000429adea...            
...                     ...                           ...       ...                                                ...         ...
45038       INITIAL STUDIES                        SCHENE  0.000017  [825a72a67aec516a82e128243373e50a9a3534c2a5a14...            
45039                SCHENE            SIGNATURE ANALYSIS  0.000017  [cb96beb68969042181d1fc56d869f58251e2cf28667c9...            
45040  DIFFERENT STRATEGIES                       II CFTR  0.000015  [1a57a8f3ba5d7f6a610e53f5dd18cce2a31bd554bc763...            
45041  DIFFERENT STRATEGIES     TRANSLATIONAL READTHROUGH  0.000015  [7c7f8c23ff390c5988bced340206ebbd3f97f54406ba7...            
45042               II CFTR               INITIAL STUDIES  0.000017  [67d27afee6109f8231b523b1e537280fe08ce4a573f17...            

[45043 rows x 5 columns]}
2025-09-08 14:40:03.0214 - INFO - graphrag.index.workflows.create_communities - Workflow started: create_communities
2025-09-08 14:40:03.0214 - INFO - graphrag.utils.storage - reading table from storage: entities.parquet
2025-09-08 14:40:03.0218 - INFO - graphrag.utils.storage - reading table from storage: relationships.parquet
2025-09-08 14:40:03.0740 - INFO - graphrag.index.workflows.create_communities - Workflow completed: create_communities
2025-09-08 14:40:03.0747 - INFO - graphrag.api.index - Workflow create_communities completed successfully
2025-09-08 14:40:03.0753 - DEBUG - graphrag.api.index -                                        id human_readable_id  ...      period size
0    8a6e6f81-cb12-4606-8eea-2235ad0f4114                 0  ...  2025-09-08  123
1    d66f82c3-2479-43db-9854-a9b85a723ded                 1  ...  2025-09-08   89
2    37935373-c1be-4132-a6c5-144a3a3444f6                 2  ...  2025-09-08   99
3    b7830d83-f059-432d-a054-705fc96eda6f                 3  ...  2025-09-08  143
4    86c7257d-fa9e-4197-b1b2-b58a046cd790                 4  ...  2025-09-08  205
..                                    ...               ...  ...         ...  ...
277  96d39afb-06d8-4846-a8f3-8d822a096d16               277  ...  2025-09-08    9
278  25096d26-0059-4d83-85e0-18c6a6a75be5               278  ...  2025-09-08    7
279  92a88c99-d8f6-4831-b61c-22bd406453e3               279  ...  2025-09-08    3
280  d467e8ee-779d-4b59-9197-5743256c5c03               280  ...  2025-09-08   11
281  c9dc78fd-1175-44bc-aa0a-195f5d234472               281  ...  2025-09-08    3

[282 rows x 12 columns]
2025-09-08 14:40:03.0753 - INFO - graphrag.index.workflows.create_final_text_units - Workflow started: create_final_text_units
2025-09-08 14:40:03.0753 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-09-08 14:40:03.0755 - INFO - graphrag.utils.storage - reading table from storage: entities.parquet
2025-09-08 14:40:03.0757 - INFO - graphrag.utils.storage - reading table from storage: relationships.parquet
2025-09-08 14:40:03.0837 - INFO - graphrag.index.workflows.create_final_text_units - Workflow completed: create_final_text_units
2025-09-08 14:40:03.0844 - INFO - graphrag.api.index - Workflow create_final_text_units completed successfully
2025-09-08 14:40:03.0849 - DEBUG - graphrag.api.index -                                                    id  ...  covariate_ids
0   accdca769e88d29b429be3731b96c5ceb2795667056e0f...  ...             []
1   bac7edde4473bb43330d983443c67f1a0c8c971b98470c...  ...             []
2   32bd73456930453483b1c170bf555ca0c614f897d8530e...  ...             []
3   cd7bf186a6dc62a0d87691b33552ebf17f2b95f7a54978...  ...             []
4   eb7c98c0364901d44179d7cf8b255eeb20293200492db8...  ...             []
..                                                ...  ...            ...
78  cb96beb68969042181d1fc56d869f58251e2cf28667c9a...  ...             []
79  857a7c9650ab3ab8c047946be4c4d17f4f89e696695997...  ...             []
80  755ba681405a00b8d303b285b82b5b25d3a53433e81659...  ...             []
81  16e9b2af109874514097d23633a85a3fbea2514b7b1257...  ...             []
82  296a2e3f40ece005fad567573f5e46631e26c1a0d657dc...  ...             []

[83 rows x 8 columns]
2025-09-08 14:40:03.0849 - INFO - graphrag.index.workflows.create_community_reports_text - Workflow started: create_community_reports_text
2025-09-08 14:40:03.0849 - INFO - graphrag.utils.storage - reading table from storage: entities.parquet
2025-09-08 14:40:03.0852 - INFO - graphrag.utils.storage - reading table from storage: communities.parquet
2025-09-08 14:40:03.0860 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-09-08 14:40:05.0866 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /Users/ctown/src/ResearchAssistantHackathon/cache/community_reporting
2025-09-08 14:40:21.0698 - INFO - graphrag.logger.progress - level 5 summarize communities progress: 1/2
2025-09-08 14:40:35.0380 - INFO - graphrag.logger.progress - level 5 summarize communities progress: 2/2
2025-09-08 14:40:46.0140 - INFO - graphrag.logger.progress - level 4 summarize communities progress: 1/31
2025-09-08 14:40:46.0782 - INFO - graphrag.logger.progress - level 4 summarize communities progress: 2/31
2025-09-08 14:40:46.0942 - INFO - graphrag.logger.progress - level 4 summarize communities progress: 3/31
2025-09-08 14:40:47.0090 - INFO - graphrag.logger.progress - level 4 summarize communities progress: 4/31
2025-09-08 14:40:47.0444 - INFO - graphrag.logger.progress - level 4 summarize communities progress: 5/31
2025-09-08 14:40:47.0536 - INFO - graphrag.logger.progress - level 4 summarize communities progress: 6/31
2025-09-08 14:40:47.0583 - INFO - graphrag.logger.progress - level 4 summarize communities progress: 7/31
2025-09-08 14:40:47.0757 - INFO - graphrag.logger.progress - level 4 summarize communities progress: 8/31
2025-09-08 14:40:47.0794 - INFO - graphrag.logger.progress - level 4 summarize communities progress: 9/31
2025-09-08 14:40:47.0876 - INFO - graphrag.logger.progress - level 4 summarize communities progress: 10/31
2025-09-08 14:40:47.0884 - INFO - graphrag.logger.progress - level 4 summarize communities progress: 11/31
2025-09-08 14:40:47.0946 - INFO - graphrag.logger.progress - level 4 summarize communities progress: 12/31
2025-09-08 14:40:48.0067 - INFO - graphrag.logger.progress - level 4 summarize communities progress: 13/31
2025-09-08 14:40:48.0210 - INFO - graphrag.logger.progress - level 4 summarize communities progress: 14/31
2025-09-08 14:40:48.0665 - INFO - graphrag.logger.progress - level 4 summarize communities progress: 15/31
2025-09-08 14:40:48.0770 - INFO - graphrag.logger.progress - level 4 summarize communities progress: 16/31
2025-09-08 14:40:48.0877 - INFO - graphrag.logger.progress - level 4 summarize communities progress: 17/31
2025-09-08 14:40:48.0930 - INFO - graphrag.logger.progress - level 4 summarize communities progress: 18/31
2025-09-08 14:40:48.0976 - INFO - graphrag.logger.progress - level 4 summarize communities progress: 19/31
2025-09-08 14:40:49.0169 - INFO - graphrag.logger.progress - level 4 summarize communities progress: 20/31
2025-09-08 14:40:49.0833 - INFO - graphrag.logger.progress - level 4 summarize communities progress: 21/31
2025-09-08 14:40:50.0830 - INFO - graphrag.logger.progress - level 4 summarize communities progress: 22/31
2025-09-08 14:40:52.0116 - INFO - graphrag.logger.progress - level 4 summarize communities progress: 23/31
2025-09-08 14:40:52.0259 - INFO - graphrag.logger.progress - level 4 summarize communities progress: 24/31
2025-09-08 14:40:58.0153 - INFO - graphrag.logger.progress - level 4 summarize communities progress: 25/31
2025-09-08 14:40:58.0178 - INFO - graphrag.logger.progress - level 4 summarize communities progress: 26/31
2025-09-08 14:40:59.0553 - INFO - graphrag.logger.progress - level 4 summarize communities progress: 27/31
2025-09-08 14:40:59.0941 - INFO - graphrag.logger.progress - level 4 summarize communities progress: 28/31
2025-09-08 14:41:00.0090 - INFO - graphrag.logger.progress - level 4 summarize communities progress: 29/31
2025-09-08 14:43:52.0457 - INFO - graphrag.logger.progress - level 4 summarize communities progress: 30/31
2025-09-08 14:44:00.0749 - INFO - graphrag.logger.progress - level 4 summarize communities progress: 31/31
2025-09-08 14:44:10.0374 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 1/123
2025-09-08 14:44:10.0480 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 2/123
2025-09-08 14:44:11.0623 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 3/123
2025-09-08 14:44:12.0774 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 4/123
2025-09-08 14:44:12.0866 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 5/123
2025-09-08 14:44:12.0880 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 6/123
2025-09-08 14:44:12.0889 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 7/123
2025-09-08 14:44:12.0897 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 8/123
2025-09-08 14:44:13.0262 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 9/123
2025-09-08 14:44:13.0299 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 10/123
2025-09-08 14:44:13.0358 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 11/123
2025-09-08 14:44:13.0506 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 12/123
2025-09-08 14:44:13.0799 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 13/123
2025-09-08 14:44:13.0979 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 14/123
2025-09-08 14:44:14.0448 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 15/123
2025-09-08 14:44:14.0703 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 16/123
2025-09-08 14:44:14.0759 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 17/123
2025-09-08 14:44:14.0826 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 18/123
2025-09-08 14:44:14.0938 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 19/123
2025-09-08 14:44:15.0147 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 20/123
2025-09-08 14:44:15.0149 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 21/123
2025-09-08 14:44:15.0187 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 22/123
2025-09-08 14:44:15.0526 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 23/123
2025-09-08 14:44:17.0470 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 24/123
2025-09-08 14:44:17.0911 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 25/123
2025-09-08 14:44:23.0352 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 26/123
2025-09-08 14:44:23.0386 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 27/123
2025-09-08 14:44:24.0236 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 28/123
2025-09-08 14:44:24.0274 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 29/123
2025-09-08 14:44:24.0420 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 30/123
2025-09-08 14:44:24.0505 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 31/123
2025-09-08 14:44:25.0441 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 32/123
2025-09-08 14:44:25.0818 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 33/123
2025-09-08 14:44:26.0265 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 34/123
2025-09-08 14:44:26.0458 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 35/123
2025-09-08 14:44:26.0907 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 36/123
2025-09-08 14:44:27.0273 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 37/123
2025-09-08 14:44:27.0522 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 38/123
2025-09-08 14:44:27.0624 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 39/123
2025-09-08 14:44:27.0685 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 40/123
2025-09-08 14:44:27.0792 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 41/123
2025-09-08 14:44:27.0888 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 42/123
2025-09-08 14:44:27.0968 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 43/123
2025-09-08 14:44:28.0027 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 44/123
2025-09-08 14:44:28.0216 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 45/123
2025-09-08 14:44:28.0280 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 46/123
2025-09-08 14:44:28.0877 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 47/123
2025-09-08 14:44:28.0906 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 48/123
2025-09-08 14:44:30.0492 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 49/123
2025-09-08 14:44:31.0356 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 50/123
2025-09-08 14:44:34.0951 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 51/123
2025-09-08 14:44:35.0966 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 52/123
2025-09-08 14:44:37.0316 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 53/123
2025-09-08 14:44:38.0764 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 54/123
2025-09-08 14:44:39.0031 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 55/123
2025-09-08 14:44:39.0197 - ERROR - graphrag.language_model.providers.fnllm.utils - Error Invoking LLM
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 4682. Please try again in 1.404s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:44:39.0199 - ERROR - graphrag.index.operations.summarize_communities.community_reports_extractor - error generating community report
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 4682. Please try again in 1.404s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:44:39.0206 - ERROR - graphrag.index.operations.summarize_communities.strategies - Community Report Extraction Error
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 4682. Please try again in 1.404s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:44:39.0207 - WARNING - graphrag.index.operations.summarize_communities.strategies - No report found for community: 209
2025-09-08 14:44:39.0207 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 56/123
2025-09-08 14:44:39.0395 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 57/123
2025-09-08 14:44:40.0430 - ERROR - graphrag.language_model.providers.fnllm.utils - Error Invoking LLM
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 4451. Please try again in 1.335s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:44:40.0432 - ERROR - graphrag.index.operations.summarize_communities.community_reports_extractor - error generating community report
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 4451. Please try again in 1.335s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:44:40.0435 - ERROR - graphrag.index.operations.summarize_communities.strategies - Community Report Extraction Error
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 4451. Please try again in 1.335s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:44:40.0437 - WARNING - graphrag.index.operations.summarize_communities.strategies - No report found for community: 223
2025-09-08 14:44:40.0438 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 58/123
2025-09-08 14:44:40.0629 - ERROR - graphrag.language_model.providers.fnllm.utils - Error Invoking LLM
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 4481. Please try again in 1.344s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:44:40.0631 - ERROR - graphrag.index.operations.summarize_communities.community_reports_extractor - error generating community report
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 4481. Please try again in 1.344s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:44:40.0634 - ERROR - graphrag.index.operations.summarize_communities.strategies - Community Report Extraction Error
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 4481. Please try again in 1.344s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:44:40.0637 - WARNING - graphrag.index.operations.summarize_communities.strategies - No report found for community: 222
2025-09-08 14:44:40.0637 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 59/123
2025-09-08 14:44:40.0763 - ERROR - graphrag.language_model.providers.fnllm.utils - Error Invoking LLM
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 4486. Please try again in 1.345s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:44:40.0765 - ERROR - graphrag.index.operations.summarize_communities.community_reports_extractor - error generating community report
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 4486. Please try again in 1.345s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:44:40.0768 - ERROR - graphrag.index.operations.summarize_communities.strategies - Community Report Extraction Error
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 4486. Please try again in 1.345s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:44:40.0769 - WARNING - graphrag.index.operations.summarize_communities.strategies - No report found for community: 224
2025-09-08 14:44:40.0770 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 60/123
2025-09-08 14:44:41.0061 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 61/123
2025-09-08 14:44:41.0506 - ERROR - graphrag.language_model.providers.fnllm.utils - Error Invoking LLM
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 4865. Please try again in 1.459s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:44:41.0507 - ERROR - graphrag.index.operations.summarize_communities.community_reports_extractor - error generating community report
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 4865. Please try again in 1.459s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:44:41.0508 - ERROR - graphrag.index.operations.summarize_communities.strategies - Community Report Extraction Error
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 4865. Please try again in 1.459s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:44:41.0509 - WARNING - graphrag.index.operations.summarize_communities.strategies - No report found for community: 217
2025-09-08 14:44:41.0509 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 62/123
2025-09-08 14:44:41.0763 - ERROR - graphrag.language_model.providers.fnllm.utils - Error Invoking LLM
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 4360. Please try again in 1.308s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:44:41.0765 - ERROR - graphrag.index.operations.summarize_communities.community_reports_extractor - error generating community report
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 4360. Please try again in 1.308s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:44:41.0769 - ERROR - graphrag.index.operations.summarize_communities.strategies - Community Report Extraction Error
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 4360. Please try again in 1.308s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:44:41.0772 - WARNING - graphrag.index.operations.summarize_communities.strategies - No report found for community: 230
2025-09-08 14:44:41.0772 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 63/123
2025-09-08 14:44:42.0243 - ERROR - graphrag.language_model.providers.fnllm.utils - Error Invoking LLM
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 4526. Please try again in 1.357s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:44:42.0246 - ERROR - graphrag.index.operations.summarize_communities.community_reports_extractor - error generating community report
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 4526. Please try again in 1.357s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:44:42.0248 - ERROR - graphrag.index.operations.summarize_communities.strategies - Community Report Extraction Error
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 4526. Please try again in 1.357s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:44:42.0250 - WARNING - graphrag.index.operations.summarize_communities.strategies - No report found for community: 229
2025-09-08 14:44:42.0251 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 64/123
2025-09-08 14:44:43.0131 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 65/123
2025-09-08 14:44:44.0360 - ERROR - graphrag.language_model.providers.fnllm.utils - Error Invoking LLM
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 195742, Requested 5725. Please try again in 440ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:44:44.0361 - ERROR - graphrag.index.operations.summarize_communities.community_reports_extractor - error generating community report
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 195742, Requested 5725. Please try again in 440ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:44:44.0364 - ERROR - graphrag.index.operations.summarize_communities.strategies - Community Report Extraction Error
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 195742, Requested 5725. Please try again in 440ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:44:44.0365 - WARNING - graphrag.index.operations.summarize_communities.strategies - No report found for community: 221
2025-09-08 14:44:44.0365 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 66/123
2025-09-08 14:44:44.0498 - ERROR - graphrag.language_model.providers.fnllm.utils - Error Invoking LLM
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 195624, Requested 5943. Please try again in 470ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:44:44.0500 - ERROR - graphrag.index.operations.summarize_communities.community_reports_extractor - error generating community report
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 195624, Requested 5943. Please try again in 470ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:44:44.0503 - ERROR - graphrag.index.operations.summarize_communities.strategies - Community Report Extraction Error
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 195624, Requested 5943. Please try again in 470ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:44:44.0505 - WARNING - graphrag.index.operations.summarize_communities.strategies - No report found for community: 219
2025-09-08 14:44:44.0506 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 67/123
2025-09-08 14:44:45.0329 - ERROR - graphrag.language_model.providers.fnllm.utils - Error Invoking LLM
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5641. Please try again in 1.692s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:44:45.0331 - ERROR - graphrag.index.operations.summarize_communities.community_reports_extractor - error generating community report
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5641. Please try again in 1.692s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:44:45.0334 - ERROR - graphrag.index.operations.summarize_communities.strategies - Community Report Extraction Error
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5641. Please try again in 1.692s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:44:45.0336 - WARNING - graphrag.index.operations.summarize_communities.strategies - No report found for community: 228
2025-09-08 14:44:45.0336 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 68/123
2025-09-08 14:44:46.0372 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 69/123
2025-09-08 14:44:46.0522 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 70/123
2025-09-08 14:44:46.0726 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 71/123
2025-09-08 14:44:48.0147 - ERROR - graphrag.language_model.providers.fnllm.utils - Error Invoking LLM
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5881. Please try again in 1.764s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:44:48.0150 - ERROR - graphrag.index.operations.summarize_communities.community_reports_extractor - error generating community report
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5881. Please try again in 1.764s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:44:48.0153 - ERROR - graphrag.index.operations.summarize_communities.strategies - Community Report Extraction Error
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5881. Please try again in 1.764s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:44:48.0156 - WARNING - graphrag.index.operations.summarize_communities.strategies - No report found for community: 234
2025-09-08 14:44:48.0157 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 72/123
2025-09-08 14:44:50.0454 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 73/123
2025-09-08 14:44:52.0691 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 74/123
2025-09-08 14:44:52.0980 - ERROR - graphrag.language_model.providers.fnllm.utils - Error Invoking LLM
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 4549. Please try again in 1.364s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:44:52.0982 - ERROR - graphrag.index.operations.summarize_communities.community_reports_extractor - error generating community report
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 4549. Please try again in 1.364s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:44:52.0984 - ERROR - graphrag.index.operations.summarize_communities.strategies - Community Report Extraction Error
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 4549. Please try again in 1.364s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:44:52.0987 - WARNING - graphrag.index.operations.summarize_communities.strategies - No report found for community: 248
2025-09-08 14:44:52.0988 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 75/123
2025-09-08 14:44:53.0897 - ERROR - graphrag.language_model.providers.fnllm.utils - Error Invoking LLM
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 6049. Please try again in 1.814s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:44:53.0900 - ERROR - graphrag.index.operations.summarize_communities.community_reports_extractor - error generating community report
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 6049. Please try again in 1.814s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:44:53.0903 - ERROR - graphrag.index.operations.summarize_communities.strategies - Community Report Extraction Error
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 6049. Please try again in 1.814s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:44:53.0906 - WARNING - graphrag.index.operations.summarize_communities.strategies - No report found for community: 132
2025-09-08 14:44:53.0906 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 76/123
2025-09-08 14:44:54.0330 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 77/123
2025-09-08 14:44:55.0290 - ERROR - graphrag.language_model.providers.fnllm.utils - Error Invoking LLM
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5541. Please try again in 1.662s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:44:55.0292 - ERROR - graphrag.index.operations.summarize_communities.community_reports_extractor - error generating community report
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5541. Please try again in 1.662s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:44:55.0296 - ERROR - graphrag.index.operations.summarize_communities.strategies - Community Report Extraction Error
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5541. Please try again in 1.662s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:44:55.0298 - WARNING - graphrag.index.operations.summarize_communities.strategies - No report found for community: 244
2025-09-08 14:44:55.0299 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 78/123
2025-09-08 14:44:55.0314 - ERROR - graphrag.language_model.providers.fnllm.utils - Error Invoking LLM
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5574. Please try again in 1.672s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:44:55.0315 - ERROR - graphrag.index.operations.summarize_communities.community_reports_extractor - error generating community report
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5574. Please try again in 1.672s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:44:55.0318 - ERROR - graphrag.index.operations.summarize_communities.strategies - Community Report Extraction Error
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5574. Please try again in 1.672s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:44:55.0319 - WARNING - graphrag.index.operations.summarize_communities.strategies - No report found for community: 241
2025-09-08 14:44:55.0319 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 79/123
2025-09-08 14:44:55.0658 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 80/123
2025-09-08 14:44:56.0313 - ERROR - graphrag.language_model.providers.fnllm.utils - Error Invoking LLM
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5827. Please try again in 1.748s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:44:56.0314 - ERROR - graphrag.index.operations.summarize_communities.community_reports_extractor - error generating community report
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5827. Please try again in 1.748s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:44:56.0317 - ERROR - graphrag.index.operations.summarize_communities.strategies - Community Report Extraction Error
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5827. Please try again in 1.748s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:44:56.0318 - WARNING - graphrag.index.operations.summarize_communities.strategies - No report found for community: 239
2025-09-08 14:44:56.0318 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 81/123
2025-09-08 14:44:56.0648 - ERROR - graphrag.language_model.providers.fnllm.utils - Error Invoking LLM
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5972. Please try again in 1.791s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:44:56.0650 - ERROR - graphrag.index.operations.summarize_communities.community_reports_extractor - error generating community report
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5972. Please try again in 1.791s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:44:56.0654 - ERROR - graphrag.index.operations.summarize_communities.strategies - Community Report Extraction Error
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5972. Please try again in 1.791s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:44:56.0657 - WARNING - graphrag.index.operations.summarize_communities.strategies - No report found for community: 129
2025-09-08 14:44:56.0657 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 82/123
2025-09-08 14:44:57.0202 - ERROR - graphrag.language_model.providers.fnllm.utils - Error Invoking LLM
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5489. Please try again in 1.646s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:44:57.0204 - ERROR - graphrag.index.operations.summarize_communities.community_reports_extractor - error generating community report
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5489. Please try again in 1.646s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:44:57.0205 - ERROR - graphrag.index.operations.summarize_communities.strategies - Community Report Extraction Error
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5489. Please try again in 1.646s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:44:57.0206 - WARNING - graphrag.index.operations.summarize_communities.strategies - No report found for community: 143
2025-09-08 14:44:57.0207 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 83/123
2025-09-08 14:44:58.0653 - ERROR - graphrag.language_model.providers.fnllm.utils - Error Invoking LLM
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5479. Please try again in 1.643s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:44:58.0655 - ERROR - graphrag.index.operations.summarize_communities.community_reports_extractor - error generating community report
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5479. Please try again in 1.643s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:44:58.0658 - ERROR - graphrag.index.operations.summarize_communities.strategies - Community Report Extraction Error
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5479. Please try again in 1.643s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:44:58.0661 - WARNING - graphrag.index.operations.summarize_communities.strategies - No report found for community: 145
2025-09-08 14:44:58.0661 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 84/123
2025-09-08 14:45:00.0135 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 85/123
2025-09-08 14:45:00.0644 - ERROR - graphrag.language_model.providers.fnllm.utils - Error Invoking LLM
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 195181, Requested 5439. Please try again in 186ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:45:00.0645 - ERROR - graphrag.index.operations.summarize_communities.community_reports_extractor - error generating community report
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 195181, Requested 5439. Please try again in 186ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:45:00.0647 - ERROR - graphrag.index.operations.summarize_communities.strategies - Community Report Extraction Error
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 195181, Requested 5439. Please try again in 186ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:45:00.0649 - WARNING - graphrag.index.operations.summarize_communities.strategies - No report found for community: 151
2025-09-08 14:45:00.0649 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 86/123
2025-09-08 14:45:00.0825 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 87/123
2025-09-08 14:45:02.0166 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 88/123
2025-09-08 14:45:03.0709 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 89/123
2025-09-08 14:45:03.0814 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 90/123
2025-09-08 14:45:04.0400 - ERROR - graphrag.language_model.providers.fnllm.utils - Error Invoking LLM
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5773. Please try again in 1.731s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:45:04.0401 - ERROR - graphrag.index.operations.summarize_communities.community_reports_extractor - error generating community report
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5773. Please try again in 1.731s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:45:04.0403 - ERROR - graphrag.index.operations.summarize_communities.strategies - Community Report Extraction Error
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5773. Please try again in 1.731s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:45:04.0404 - WARNING - graphrag.index.operations.summarize_communities.strategies - No report found for community: 167
2025-09-08 14:45:04.0404 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 91/123
2025-09-08 14:45:05.0362 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 92/123
2025-09-08 14:45:05.0529 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 93/123
2025-09-08 14:45:06.0030 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 94/123
2025-09-08 14:45:07.0674 - ERROR - graphrag.language_model.providers.fnllm.utils - Error Invoking LLM
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5588. Please try again in 1.676s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:45:07.0677 - ERROR - graphrag.index.operations.summarize_communities.community_reports_extractor - error generating community report
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5588. Please try again in 1.676s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:45:07.0679 - ERROR - graphrag.index.operations.summarize_communities.strategies - Community Report Extraction Error
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5588. Please try again in 1.676s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:45:07.0680 - WARNING - graphrag.index.operations.summarize_communities.strategies - No report found for community: 175
2025-09-08 14:45:07.0680 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 95/123
2025-09-08 14:45:08.0049 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 96/123
2025-09-08 14:45:09.0604 - ERROR - graphrag.language_model.providers.fnllm.utils - Error Invoking LLM
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5628. Please try again in 1.688s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:45:09.0606 - ERROR - graphrag.index.operations.summarize_communities.community_reports_extractor - error generating community report
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5628. Please try again in 1.688s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:45:09.0609 - ERROR - graphrag.index.operations.summarize_communities.strategies - Community Report Extraction Error
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5628. Please try again in 1.688s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:45:09.0611 - WARNING - graphrag.index.operations.summarize_communities.strategies - No report found for community: 181
2025-09-08 14:45:09.0612 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 97/123
2025-09-08 14:45:10.0058 - ERROR - graphrag.language_model.providers.fnllm.utils - Error Invoking LLM
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5789. Please try again in 1.736s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:45:10.0059 - ERROR - graphrag.index.operations.summarize_communities.community_reports_extractor - error generating community report
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5789. Please try again in 1.736s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:45:10.0061 - ERROR - graphrag.index.operations.summarize_communities.strategies - Community Report Extraction Error
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5789. Please try again in 1.736s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:45:10.0063 - WARNING - graphrag.index.operations.summarize_communities.strategies - No report found for community: 177
2025-09-08 14:45:10.0063 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 98/123
2025-09-08 14:45:11.0595 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 99/123
2025-09-08 14:45:12.0772 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 100/123
2025-09-08 14:45:13.0041 - ERROR - graphrag.language_model.providers.fnllm.utils - Error Invoking LLM
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 194779, Requested 5610. Please try again in 116ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:45:13.0043 - ERROR - graphrag.index.operations.summarize_communities.community_reports_extractor - error generating community report
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 194779, Requested 5610. Please try again in 116ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:45:13.0046 - ERROR - graphrag.index.operations.summarize_communities.strategies - Community Report Extraction Error
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 194779, Requested 5610. Please try again in 116ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:45:13.0047 - WARNING - graphrag.index.operations.summarize_communities.strategies - No report found for community: 190
2025-09-08 14:45:13.0048 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 101/123
2025-09-08 14:45:13.0287 - ERROR - graphrag.language_model.providers.fnllm.utils - Error Invoking LLM
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 194196, Requested 5857. Please try again in 15ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:45:13.0288 - ERROR - graphrag.index.operations.summarize_communities.community_reports_extractor - error generating community report
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 194196, Requested 5857. Please try again in 15ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:45:13.0291 - ERROR - graphrag.index.operations.summarize_communities.strategies - Community Report Extraction Error
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 194196, Requested 5857. Please try again in 15ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:45:13.0293 - WARNING - graphrag.index.operations.summarize_communities.strategies - No report found for community: 183
2025-09-08 14:45:13.0293 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 102/123
2025-09-08 14:45:13.0448 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 103/123
2025-09-08 14:45:14.0226 - ERROR - graphrag.language_model.providers.fnllm.utils - Error Invoking LLM
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5171. Please try again in 1.551s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:45:14.0229 - ERROR - graphrag.index.operations.summarize_communities.community_reports_extractor - error generating community report
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5171. Please try again in 1.551s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:45:14.0233 - ERROR - graphrag.index.operations.summarize_communities.strategies - Community Report Extraction Error
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5171. Please try again in 1.551s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:45:14.0236 - WARNING - graphrag.index.operations.summarize_communities.strategies - No report found for community: 202
2025-09-08 14:45:14.0236 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 104/123
2025-09-08 14:45:14.0929 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 105/123
2025-09-08 14:45:15.0198 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 106/123
2025-09-08 14:45:15.0373 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 107/123
2025-09-08 14:45:16.0196 - ERROR - graphrag.language_model.providers.fnllm.utils - Error Invoking LLM
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5171. Please try again in 1.551s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:45:16.0197 - ERROR - graphrag.index.operations.summarize_communities.community_reports_extractor - error generating community report
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5171. Please try again in 1.551s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:45:16.0199 - ERROR - graphrag.index.operations.summarize_communities.strategies - Community Report Extraction Error
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5171. Please try again in 1.551s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:45:16.0200 - WARNING - graphrag.index.operations.summarize_communities.strategies - No report found for community: 203
2025-09-08 14:45:16.0200 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 108/123
2025-09-08 14:45:16.0301 - ERROR - graphrag.language_model.providers.fnllm.utils - Error Invoking LLM
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5955. Please try again in 1.786s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:45:16.0302 - ERROR - graphrag.index.operations.summarize_communities.community_reports_extractor - error generating community report
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5955. Please try again in 1.786s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:45:16.0304 - ERROR - graphrag.index.operations.summarize_communities.strategies - Community Report Extraction Error
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5955. Please try again in 1.786s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:45:16.0305 - WARNING - graphrag.index.operations.summarize_communities.strategies - No report found for community: 196
2025-09-08 14:45:16.0305 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 109/123
2025-09-08 14:45:17.0104 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 110/123
2025-09-08 14:45:19.0129 - ERROR - graphrag.language_model.providers.fnllm.utils - Error Invoking LLM
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 4715. Please try again in 1.414s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:45:19.0131 - ERROR - graphrag.index.operations.summarize_communities.community_reports_extractor - error generating community report
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 4715. Please try again in 1.414s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:45:19.0134 - ERROR - graphrag.index.operations.summarize_communities.strategies - Community Report Extraction Error
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 4715. Please try again in 1.414s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:45:19.0137 - WARNING - graphrag.index.operations.summarize_communities.strategies - No report found for community: 218
2025-09-08 14:45:19.0137 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 111/123
2025-09-08 14:45:20.0781 - ERROR - graphrag.language_model.providers.fnllm.utils - Error Invoking LLM
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 6128. Please try again in 1.838s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:45:20.0783 - ERROR - graphrag.index.operations.summarize_communities.community_reports_extractor - error generating community report
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 6128. Please try again in 1.838s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:45:20.0785 - ERROR - graphrag.index.operations.summarize_communities.strategies - Community Report Extraction Error
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 6128. Please try again in 1.838s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:45:20.0787 - WARNING - graphrag.index.operations.summarize_communities.strategies - No report found for community: 211
2025-09-08 14:45:20.0787 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 112/123
2025-09-08 14:45:20.0982 - ERROR - graphrag.language_model.providers.fnllm.utils - Error Invoking LLM
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 6197. Please try again in 1.859s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:45:20.0985 - ERROR - graphrag.index.operations.summarize_communities.community_reports_extractor - error generating community report
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 6197. Please try again in 1.859s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:45:20.0987 - ERROR - graphrag.index.operations.summarize_communities.strategies - Community Report Extraction Error
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 6197. Please try again in 1.859s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:45:20.0988 - WARNING - graphrag.index.operations.summarize_communities.strategies - No report found for community: 210
2025-09-08 14:45:20.0988 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 113/123
2025-09-08 14:45:22.0130 - ERROR - graphrag.language_model.providers.fnllm.utils - Error Invoking LLM
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5710. Please try again in 1.713s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:45:22.0132 - ERROR - graphrag.index.operations.summarize_communities.community_reports_extractor - error generating community report
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5710. Please try again in 1.713s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:45:22.0135 - ERROR - graphrag.index.operations.summarize_communities.strategies - Community Report Extraction Error
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5710. Please try again in 1.713s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:45:22.0137 - WARNING - graphrag.index.operations.summarize_communities.strategies - No report found for community: 225
2025-09-08 14:45:22.0138 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 114/123
2025-09-08 14:45:23.0714 - ERROR - graphrag.language_model.providers.fnllm.utils - Error Invoking LLM
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 195446, Requested 5597. Please try again in 312ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:45:23.0716 - ERROR - graphrag.index.operations.summarize_communities.community_reports_extractor - error generating community report
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 195446, Requested 5597. Please try again in 312ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:45:23.0719 - ERROR - graphrag.index.operations.summarize_communities.strategies - Community Report Extraction Error
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 195446, Requested 5597. Please try again in 312ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:45:23.0720 - WARNING - graphrag.index.operations.summarize_communities.strategies - No report found for community: 232
2025-09-08 14:45:23.0720 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 115/123
2025-09-08 14:45:25.0757 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 116/123
2025-09-08 14:45:26.0221 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 117/123
2025-09-08 14:45:28.0316 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 118/123
2025-09-08 14:45:29.0580 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 119/123
2025-09-08 14:45:32.0649 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 120/123
2025-09-08 14:45:33.0831 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 121/123
2025-09-08 14:45:38.0420 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 122/123
2025-09-08 14:47:57.0661 - INFO - graphrag.logger.progress - level 3 summarize communities progress: 123/123
2025-09-08 14:48:05.0789 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 1/86
2025-09-08 14:48:06.0399 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 2/86
2025-09-08 14:48:06.0884 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 3/86
2025-09-08 14:48:07.0326 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 4/86
2025-09-08 14:48:08.0088 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 5/86
2025-09-08 14:48:08.0337 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 6/86
2025-09-08 14:48:08.0533 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 7/86
2025-09-08 14:48:08.0662 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 8/86
2025-09-08 14:48:09.0029 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 9/86
2025-09-08 14:48:09.0062 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 10/86
2025-09-08 14:48:09.0116 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 11/86
2025-09-08 14:48:09.0437 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 12/86
2025-09-08 14:48:09.0648 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 13/86
2025-09-08 14:48:09.0754 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 14/86
2025-09-08 14:48:10.0161 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 15/86
2025-09-08 14:48:10.0224 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 16/86
2025-09-08 14:48:10.0555 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 17/86
2025-09-08 14:48:10.0695 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 18/86
2025-09-08 14:48:11.0065 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 19/86
2025-09-08 14:48:11.0936 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 20/86
2025-09-08 14:48:11.0993 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 21/86
2025-09-08 14:48:12.0653 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 22/86
2025-09-08 14:48:12.0805 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 23/86
2025-09-08 14:48:14.0485 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 24/86
2025-09-08 14:48:15.0289 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 25/86
2025-09-08 14:48:28.0026 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 26/86
2025-09-08 14:48:29.0495 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 27/86
2025-09-08 14:48:31.0396 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 28/86
2025-09-08 14:48:31.0462 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 29/86
2025-09-08 14:48:31.0564 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 30/86
2025-09-08 14:48:32.0064 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 31/86
2025-09-08 14:48:32.0180 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 32/86
2025-09-08 14:48:33.0473 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 33/86
2025-09-08 14:48:34.0217 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 34/86
2025-09-08 14:48:34.0475 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 35/86
2025-09-08 14:48:35.0005 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 36/86
2025-09-08 14:48:35.0506 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 37/86
2025-09-08 14:48:35.0645 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 38/86
2025-09-08 14:48:36.0532 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 39/86
2025-09-08 14:48:36.0619 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 40/86
2025-09-08 14:48:36.0839 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 41/86
2025-09-08 14:48:37.0541 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 42/86
2025-09-08 14:48:37.0881 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 43/86
2025-09-08 14:48:38.0707 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 44/86
2025-09-08 14:48:40.0115 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 45/86
2025-09-08 14:48:41.0133 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 46/86
2025-09-08 14:48:42.0296 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 47/86
2025-09-08 14:48:42.0992 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 48/86
2025-09-08 14:48:43.0115 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 49/86
2025-09-08 14:48:44.0066 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 50/86
2025-09-08 14:48:48.0839 - ERROR - graphrag.language_model.providers.fnllm.utils - Error Invoking LLM
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 199402, Requested 5332. Please try again in 1.42s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:48:48.0842 - ERROR - graphrag.index.operations.summarize_communities.community_reports_extractor - error generating community report
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 199402, Requested 5332. Please try again in 1.42s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:48:48.0845 - ERROR - graphrag.index.operations.summarize_communities.strategies - Community Report Extraction Error
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 199402, Requested 5332. Please try again in 1.42s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:48:48.0848 - WARNING - graphrag.index.operations.summarize_communities.strategies - No report found for community: 96
2025-09-08 14:48:48.0849 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 51/86
2025-09-08 14:48:50.0395 - ERROR - graphrag.language_model.providers.fnllm.utils - Error Invoking LLM
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5171. Please try again in 1.551s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:48:50.0397 - ERROR - graphrag.index.operations.summarize_communities.community_reports_extractor - error generating community report
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5171. Please try again in 1.551s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:48:50.0399 - ERROR - graphrag.index.operations.summarize_communities.strategies - Community Report Extraction Error
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5171. Please try again in 1.551s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:48:50.0402 - WARNING - graphrag.index.operations.summarize_communities.strategies - No report found for community: 97
2025-09-08 14:48:50.0402 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 52/86
2025-09-08 14:48:50.0436 - ERROR - graphrag.language_model.providers.fnllm.utils - Error Invoking LLM
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5539. Please try again in 1.661s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:48:50.0437 - ERROR - graphrag.index.operations.summarize_communities.community_reports_extractor - error generating community report
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5539. Please try again in 1.661s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:48:50.0439 - ERROR - graphrag.index.operations.summarize_communities.strategies - Community Report Extraction Error
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5539. Please try again in 1.661s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:48:50.0440 - WARNING - graphrag.index.operations.summarize_communities.strategies - No report found for community: 99
2025-09-08 14:48:50.0440 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 53/86
2025-09-08 14:48:50.0686 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 54/86
2025-09-08 14:48:52.0809 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 55/86
2025-09-08 14:48:52.0983 - ERROR - graphrag.language_model.providers.fnllm.utils - Error Invoking LLM
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 6099. Please try again in 1.829s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:48:52.0986 - ERROR - graphrag.index.operations.summarize_communities.community_reports_extractor - error generating community report
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 6099. Please try again in 1.829s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:48:52.0988 - ERROR - graphrag.index.operations.summarize_communities.strategies - Community Report Extraction Error
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 6099. Please try again in 1.829s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:48:52.0989 - WARNING - graphrag.index.operations.summarize_communities.strategies - No report found for community: 101
2025-09-08 14:48:52.0989 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 56/86
2025-09-08 14:48:53.0534 - ERROR - graphrag.language_model.providers.fnllm.utils - Error Invoking LLM
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5141. Please try again in 1.542s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:48:53.0536 - ERROR - graphrag.index.operations.summarize_communities.community_reports_extractor - error generating community report
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5141. Please try again in 1.542s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:48:53.0539 - ERROR - graphrag.index.operations.summarize_communities.strategies - Community Report Extraction Error
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5141. Please try again in 1.542s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:48:53.0540 - WARNING - graphrag.index.operations.summarize_communities.strategies - No report found for community: 106
2025-09-08 14:48:53.0540 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 57/86
2025-09-08 14:48:54.0850 - ERROR - graphrag.language_model.providers.fnllm.utils - Error Invoking LLM
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 6198. Please try again in 1.859s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:48:54.0852 - ERROR - graphrag.index.operations.summarize_communities.community_reports_extractor - error generating community report
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 6198. Please try again in 1.859s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:48:54.0855 - ERROR - graphrag.index.operations.summarize_communities.strategies - Community Report Extraction Error
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 6198. Please try again in 1.859s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:48:54.0856 - WARNING - graphrag.index.operations.summarize_communities.strategies - No report found for community: 102
2025-09-08 14:48:54.0857 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 58/86
2025-09-08 14:48:55.0515 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 59/86
2025-09-08 14:48:56.0978 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 60/86
2025-09-08 14:48:57.0848 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 61/86
2025-09-08 14:48:58.0058 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 62/86
2025-09-08 14:48:58.0594 - ERROR - graphrag.language_model.providers.fnllm.utils - Error Invoking LLM
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 196323, Requested 5169. Please try again in 447ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:48:58.0596 - ERROR - graphrag.index.operations.summarize_communities.community_reports_extractor - error generating community report
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 196323, Requested 5169. Please try again in 447ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:48:58.0599 - ERROR - graphrag.index.operations.summarize_communities.strategies - Community Report Extraction Error
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 196323, Requested 5169. Please try again in 447ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:48:58.0600 - WARNING - graphrag.index.operations.summarize_communities.strategies - No report found for community: 111
2025-09-08 14:48:58.0600 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 63/86
2025-09-08 14:48:59.0211 - ERROR - graphrag.language_model.providers.fnllm.utils - Error Invoking LLM
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 194819, Requested 5578. Please try again in 119ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:48:59.0213 - ERROR - graphrag.index.operations.summarize_communities.community_reports_extractor - error generating community report
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 194819, Requested 5578. Please try again in 119ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:48:59.0215 - ERROR - graphrag.index.operations.summarize_communities.strategies - Community Report Extraction Error
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 194819, Requested 5578. Please try again in 119ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:48:59.0216 - WARNING - graphrag.index.operations.summarize_communities.strategies - No report found for community: 110
2025-09-08 14:48:59.0216 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 64/86
2025-09-08 14:48:59.0475 - ERROR - graphrag.language_model.providers.fnllm.utils - Error Invoking LLM
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 199042, Requested 5693. Please try again in 1.42s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:48:59.0477 - ERROR - graphrag.index.operations.summarize_communities.community_reports_extractor - error generating community report
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 199042, Requested 5693. Please try again in 1.42s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:48:59.0479 - ERROR - graphrag.index.operations.summarize_communities.strategies - Community Report Extraction Error
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 199042, Requested 5693. Please try again in 1.42s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:48:59.0480 - WARNING - graphrag.index.operations.summarize_communities.strategies - No report found for community: 112
2025-09-08 14:48:59.0480 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 65/86
2025-09-08 14:48:59.0678 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 66/86
2025-09-08 14:48:59.0965 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 67/86
2025-09-08 14:49:01.0942 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 68/86
2025-09-08 14:49:02.0719 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 69/86
2025-09-08 14:49:03.0970 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 70/86
2025-09-08 14:49:04.0295 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 71/86
2025-09-08 14:49:04.0788 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 72/86
2025-09-08 14:49:04.0834 - ERROR - graphrag.language_model.providers.fnllm.utils - Error Invoking LLM
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5665. Please try again in 1.699s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:49:04.0836 - ERROR - graphrag.index.operations.summarize_communities.community_reports_extractor - error generating community report
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5665. Please try again in 1.699s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:49:04.0839 - ERROR - graphrag.index.operations.summarize_communities.strategies - Community Report Extraction Error
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5665. Please try again in 1.699s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:49:04.0842 - WARNING - graphrag.index.operations.summarize_communities.strategies - No report found for community: 117
2025-09-08 14:49:04.0842 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 73/86
2025-09-08 14:49:05.0454 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 74/86
2025-09-08 14:49:06.0828 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 75/86
2025-09-08 14:49:08.0280 - ERROR - graphrag.language_model.providers.fnllm.utils - Error Invoking LLM
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5826. Please try again in 1.747s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:49:08.0283 - ERROR - graphrag.index.operations.summarize_communities.community_reports_extractor - error generating community report
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5826. Please try again in 1.747s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:49:08.0287 - ERROR - graphrag.index.operations.summarize_communities.strategies - Community Report Extraction Error
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5826. Please try again in 1.747s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:49:08.0289 - WARNING - graphrag.index.operations.summarize_communities.strategies - No report found for community: 119
2025-09-08 14:49:08.0290 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 76/86
2025-09-08 14:49:08.0557 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 77/86
2025-09-08 14:49:08.0917 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 78/86
2025-09-08 14:49:11.0308 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 79/86
2025-09-08 14:49:11.0428 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 80/86
2025-09-08 14:49:11.0452 - ERROR - graphrag.language_model.providers.fnllm.utils - Error Invoking LLM
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5497. Please try again in 1.649s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:49:11.0453 - ERROR - graphrag.index.operations.summarize_communities.community_reports_extractor - error generating community report
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5497. Please try again in 1.649s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:49:11.0456 - ERROR - graphrag.index.operations.summarize_communities.strategies - Community Report Extraction Error
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 200000, Requested 5497. Please try again in 1.649s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:49:11.0458 - WARNING - graphrag.index.operations.summarize_communities.strategies - No report found for community: 123
2025-09-08 14:49:11.0458 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 81/86
2025-09-08 14:49:13.0316 - ERROR - graphrag.language_model.providers.fnllm.utils - Error Invoking LLM
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 195242, Requested 5742. Please try again in 295ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:49:13.0318 - ERROR - graphrag.index.operations.summarize_communities.community_reports_extractor - error generating community report
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 195242, Requested 5742. Please try again in 295ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:49:13.0321 - ERROR - graphrag.index.operations.summarize_communities.strategies - Community Report Extraction Error
Traceback (most recent call last):
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctown/src/ResearchAssistantHackathon/graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1-nano in organization org-FPfApYqu4Hy2dNJnjHxLENjp on tokens per min (TPM): Limit 200000, Used 195242, Requested 5742. Please try again in 295ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-08 14:49:13.0323 - WARNING - graphrag.index.operations.summarize_communities.strategies - No report found for community: 125
2025-09-08 14:49:13.0324 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 82/86
2025-09-08 14:49:14.0830 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 83/86
2025-09-08 14:49:14.0939 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 84/86
2025-09-08 14:49:17.0637 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 85/86
2025-09-08 14:52:20.0845 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 86/86
2025-09-08 14:52:32.0411 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 1/32
2025-09-08 14:52:33.0503 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 2/32
2025-09-08 14:52:33.0759 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 3/32
2025-09-08 14:52:33.0841 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 4/32
2025-09-08 14:52:34.0216 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 5/32
2025-09-08 14:52:34.0264 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 6/32
2025-09-08 14:52:34.0411 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 7/32
2025-09-08 14:52:34.0918 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 8/32
2025-09-08 14:52:34.0970 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 9/32
2025-09-08 14:52:35.0229 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 10/32
2025-09-08 14:52:35.0632 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 11/32
2025-09-08 14:52:35.0703 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 12/32
2025-09-08 14:52:35.0902 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 13/32
2025-09-08 14:52:35.0919 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 14/32
2025-09-08 14:52:36.0104 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 15/32
2025-09-08 14:52:36.0316 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 16/32
2025-09-08 14:52:37.0174 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 17/32
2025-09-08 14:52:37.0470 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 18/32
2025-09-08 14:52:37.0894 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 19/32
2025-09-08 14:52:37.0968 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 20/32
2025-09-08 14:52:38.0466 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 21/32
2025-09-08 14:52:40.0132 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 22/32
2025-09-08 14:52:40.0168 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 23/32
2025-09-08 14:52:40.0572 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 24/32
2025-09-08 14:52:40.0884 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 25/32
2025-09-08 14:52:48.0238 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 26/32
2025-09-08 14:52:48.0239 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 27/32
2025-09-08 14:52:48.0275 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 28/32
2025-09-08 14:52:49.0385 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 29/32
2025-09-08 14:52:49.0497 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 30/32
2025-09-08 14:52:51.0041 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 31/32
2025-09-08 14:52:53.0695 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 32/32
2025-09-08 14:53:06.0540 - INFO - graphrag.logger.progress - level 0 summarize communities progress: 1/8
2025-09-08 14:53:07.0159 - INFO - graphrag.logger.progress - level 0 summarize communities progress: 2/8
2025-09-08 14:53:07.0512 - INFO - graphrag.logger.progress - level 0 summarize communities progress: 3/8
2025-09-08 14:53:07.0559 - INFO - graphrag.logger.progress - level 0 summarize communities progress: 4/8
2025-09-08 14:53:07.0966 - INFO - graphrag.logger.progress - level 0 summarize communities progress: 5/8
2025-09-08 14:53:07.0996 - INFO - graphrag.logger.progress - level 0 summarize communities progress: 6/8
2025-09-08 14:53:09.0046 - INFO - graphrag.logger.progress - level 0 summarize communities progress: 7/8
2025-09-08 14:53:13.0702 - INFO - graphrag.logger.progress - level 0 summarize communities progress: 8/8
2025-09-08 14:53:13.0747 - INFO - graphrag.index.workflows.create_community_reports_text - Workflow completed: create_community_reports_text
2025-09-08 14:53:13.0761 - INFO - graphrag.api.index - Workflow create_community_reports_text completed successfully
2025-09-08 14:53:13.0770 - DEBUG - graphrag.api.index -                                    id  human_readable_id  ...      period  size
0    903355ba0b6643f18da45c65f5feb6cb                280  ...  2025-09-08    11
1    8458fb09e46843fbb917ddd02cf3a6bc                281  ...  2025-09-08     3
2    38426d6e4c05415eba74fe4f835ca244                250  ...  2025-09-08     7
3    fd473d3f912a4404bb27e67bc054dcad                251  ...  2025-09-08     3
4    2aa3ff9017174d2da012dfb2f4f12e0e                253  ...  2025-09-08     5
..                                ...                ...  ...         ...   ...
230  16c70ffb33514d5d89c3e04bb3849cc6                  3  ...  2025-09-08   143
231  0617e8fe4adb44eab660073aed6b4b80                  4  ...  2025-09-08   205
232  21a3d9df8f88441bab01e8288209d619                  5  ...  2025-09-08   154
233  4a12e4ec29df4b9ca38c292907090e8f                  6  ...  2025-09-08   117
234  3d98de1dfdf74ff285052449034a50c7                  7  ...  2025-09-08   219

[235 rows x 15 columns]
2025-09-08 14:53:13.0770 - INFO - graphrag.index.workflows.generate_text_embeddings - Workflow started: generate_text_embeddings
2025-09-08 14:53:13.0770 - INFO - graphrag.index.workflows.generate_text_embeddings - Embedding the following fields: ['entity.description', 'community.full_content', 'text_unit.text']
2025-09-08 14:53:13.0770 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-09-08 14:53:13.0782 - INFO - graphrag.utils.storage - reading table from storage: entities.parquet
2025-09-08 14:53:13.0786 - INFO - graphrag.utils.storage - reading table from storage: community_reports.parquet
2025-09-08 14:53:13.0792 - INFO - graphrag.index.workflows.generate_text_embeddings - Creating embeddings
2025-09-08 14:53:13.0792 - INFO - graphrag.index.operations.embed_text.embed_text - using vector store lancedb with container_name default for embedding entity.description: default-entity-description
2025-09-08 14:53:13.0804 - INFO - graphrag.index.operations.embed_text.embed_text - uploading text embeddings batch 1/3 of size 500 to vector store
2025-09-08 14:53:13.0805 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /Users/ctown/src/ResearchAssistantHackathon/cache/text_embedding
2025-09-08 14:53:13.0827 - INFO - graphrag.index.operations.embed_text.strategies.openai - embedding 500 inputs via 500 snippets using 32 batches. max_batch_size=16, batch_max_tokens=8191
2025-09-08 14:53:14.0231 - INFO - graphrag.logger.progress - generate embeddings progress: 1/32
2025-09-08 14:53:14.0241 - INFO - graphrag.logger.progress - generate embeddings progress: 2/32
2025-09-08 14:53:14.0242 - INFO - graphrag.logger.progress - generate embeddings progress: 3/32
2025-09-08 14:53:14.0243 - INFO - graphrag.logger.progress - generate embeddings progress: 4/32
2025-09-08 14:53:14.0244 - INFO - graphrag.logger.progress - generate embeddings progress: 5/32
2025-09-08 14:53:14.0260 - INFO - graphrag.logger.progress - generate embeddings progress: 6/32
2025-09-08 14:53:14.0261 - INFO - graphrag.logger.progress - generate embeddings progress: 7/32
2025-09-08 14:53:14.0263 - INFO - graphrag.logger.progress - generate embeddings progress: 8/32
2025-09-08 14:53:14.0266 - INFO - graphrag.logger.progress - generate embeddings progress: 9/32
2025-09-08 14:53:14.0290 - INFO - graphrag.logger.progress - generate embeddings progress: 10/32
2025-09-08 14:53:14.0355 - INFO - graphrag.logger.progress - generate embeddings progress: 11/32
2025-09-08 14:53:14.0459 - INFO - graphrag.logger.progress - generate embeddings progress: 12/32
2025-09-08 14:53:14.0460 - INFO - graphrag.logger.progress - generate embeddings progress: 13/32
2025-09-08 14:53:14.0461 - INFO - graphrag.logger.progress - generate embeddings progress: 14/32
2025-09-08 14:53:14.0570 - INFO - graphrag.logger.progress - generate embeddings progress: 15/32
2025-09-08 14:53:14.0600 - INFO - graphrag.logger.progress - generate embeddings progress: 16/32
2025-09-08 14:53:14.0601 - INFO - graphrag.logger.progress - generate embeddings progress: 17/32
2025-09-08 14:53:14.0659 - INFO - graphrag.logger.progress - generate embeddings progress: 18/32
2025-09-08 14:53:14.0661 - INFO - graphrag.logger.progress - generate embeddings progress: 19/32
2025-09-08 14:53:14.0662 - INFO - graphrag.logger.progress - generate embeddings progress: 20/32
2025-09-08 14:53:14.0672 - INFO - graphrag.logger.progress - generate embeddings progress: 21/32
2025-09-08 14:53:14.0674 - INFO - graphrag.logger.progress - generate embeddings progress: 22/32
2025-09-08 14:53:14.0692 - INFO - graphrag.logger.progress - generate embeddings progress: 23/32
2025-09-08 14:53:14.0751 - INFO - graphrag.logger.progress - generate embeddings progress: 24/32
2025-09-08 14:53:14.0772 - INFO - graphrag.logger.progress - generate embeddings progress: 25/32
2025-09-08 14:53:14.0868 - INFO - graphrag.logger.progress - generate embeddings progress: 26/32
2025-09-08 14:53:15.0035 - INFO - graphrag.logger.progress - generate embeddings progress: 27/32
2025-09-08 14:53:15.0036 - INFO - graphrag.logger.progress - generate embeddings progress: 28/32
2025-09-08 14:53:15.0053 - INFO - graphrag.logger.progress - generate embeddings progress: 29/32
2025-09-08 14:53:15.0199 - INFO - graphrag.logger.progress - generate embeddings progress: 30/32
2025-09-08 14:53:15.0200 - INFO - graphrag.logger.progress - generate embeddings progress: 31/32
2025-09-08 14:53:15.0244 - INFO - graphrag.logger.progress - generate embeddings progress: 32/32
2025-09-08 14:53:15.0312 - INFO - graphrag.index.operations.embed_text.embed_text - uploading text embeddings batch 2/3 of size 500 to vector store
2025-09-08 14:53:15.0317 - INFO - graphrag.index.operations.embed_text.strategies.openai - embedding 500 inputs via 500 snippets using 32 batches. max_batch_size=16, batch_max_tokens=8191
2025-09-08 14:53:15.0584 - INFO - graphrag.logger.progress - generate embeddings progress: 1/32
2025-09-08 14:53:15.0586 - INFO - graphrag.logger.progress - generate embeddings progress: 2/32
2025-09-08 14:53:15.0609 - INFO - graphrag.logger.progress - generate embeddings progress: 3/32
2025-09-08 14:53:15.0633 - INFO - graphrag.logger.progress - generate embeddings progress: 4/32
2025-09-08 14:53:15.0634 - INFO - graphrag.logger.progress - generate embeddings progress: 5/32
2025-09-08 14:53:15.0663 - INFO - graphrag.logger.progress - generate embeddings progress: 6/32
2025-09-08 14:53:15.0708 - INFO - graphrag.logger.progress - generate embeddings progress: 7/32
2025-09-08 14:53:15.0708 - INFO - graphrag.logger.progress - generate embeddings progress: 8/32
2025-09-08 14:53:15.0717 - INFO - graphrag.logger.progress - generate embeddings progress: 9/32
2025-09-08 14:53:15.0746 - INFO - graphrag.logger.progress - generate embeddings progress: 10/32
2025-09-08 14:53:15.0747 - INFO - graphrag.logger.progress - generate embeddings progress: 11/32
2025-09-08 14:53:15.0771 - INFO - graphrag.logger.progress - generate embeddings progress: 12/32
2025-09-08 14:53:15.0772 - INFO - graphrag.logger.progress - generate embeddings progress: 13/32
2025-09-08 14:53:15.0772 - INFO - graphrag.logger.progress - generate embeddings progress: 14/32
2025-09-08 14:53:15.0784 - INFO - graphrag.logger.progress - generate embeddings progress: 15/32
2025-09-08 14:53:15.0784 - INFO - graphrag.logger.progress - generate embeddings progress: 16/32
2025-09-08 14:53:15.0785 - INFO - graphrag.logger.progress - generate embeddings progress: 17/32
2025-09-08 14:53:15.0825 - INFO - graphrag.logger.progress - generate embeddings progress: 18/32
2025-09-08 14:53:15.0847 - INFO - graphrag.logger.progress - generate embeddings progress: 19/32
2025-09-08 14:53:15.0868 - INFO - graphrag.logger.progress - generate embeddings progress: 20/32
2025-09-08 14:53:15.0869 - INFO - graphrag.logger.progress - generate embeddings progress: 21/32
2025-09-08 14:53:15.0916 - INFO - graphrag.logger.progress - generate embeddings progress: 22/32
2025-09-08 14:53:15.0917 - INFO - graphrag.logger.progress - generate embeddings progress: 23/32
2025-09-08 14:53:15.0937 - INFO - graphrag.logger.progress - generate embeddings progress: 24/32
2025-09-08 14:53:15.0967 - INFO - graphrag.logger.progress - generate embeddings progress: 25/32
2025-09-08 14:53:15.0969 - INFO - graphrag.logger.progress - generate embeddings progress: 26/32
2025-09-08 14:53:15.0999 - INFO - graphrag.logger.progress - generate embeddings progress: 27/32
2025-09-08 14:53:16.0020 - INFO - graphrag.logger.progress - generate embeddings progress: 28/32
2025-09-08 14:53:16.0033 - INFO - graphrag.logger.progress - generate embeddings progress: 29/32
2025-09-08 14:53:16.0107 - INFO - graphrag.logger.progress - generate embeddings progress: 30/32
2025-09-08 14:53:16.0680 - INFO - graphrag.logger.progress - generate embeddings progress: 31/32
2025-09-08 14:53:17.0530 - INFO - graphrag.logger.progress - generate embeddings progress: 32/32
2025-09-08 14:53:17.0580 - INFO - graphrag.index.operations.embed_text.embed_text - uploading text embeddings batch 3/3 of size 500 to vector store
2025-09-08 14:53:17.0582 - INFO - graphrag.index.operations.embed_text.strategies.openai - embedding 149 inputs via 149 snippets using 10 batches. max_batch_size=16, batch_max_tokens=8191
2025-09-08 14:53:17.0761 - INFO - graphrag.logger.progress - generate embeddings progress: 1/10
2025-09-08 14:53:17.0824 - INFO - graphrag.logger.progress - generate embeddings progress: 2/10
2025-09-08 14:53:17.0928 - INFO - graphrag.logger.progress - generate embeddings progress: 3/10
2025-09-08 14:53:17.0976 - INFO - graphrag.logger.progress - generate embeddings progress: 4/10
2025-09-08 14:53:18.0042 - INFO - graphrag.logger.progress - generate embeddings progress: 5/10
2025-09-08 14:53:18.0045 - INFO - graphrag.logger.progress - generate embeddings progress: 6/10
2025-09-08 14:53:18.0046 - INFO - graphrag.logger.progress - generate embeddings progress: 7/10
2025-09-08 14:53:18.0070 - INFO - graphrag.logger.progress - generate embeddings progress: 8/10
2025-09-08 14:53:18.0127 - INFO - graphrag.logger.progress - generate embeddings progress: 9/10
2025-09-08 14:53:18.0145 - INFO - graphrag.logger.progress - generate embeddings progress: 10/10
2025-09-08 14:53:18.0164 - INFO - graphrag.index.operations.embed_text.embed_text - using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
2025-09-08 14:53:18.0165 - INFO - graphrag.index.operations.embed_text.embed_text - uploading text embeddings batch 1/1 of size 500 to vector store
2025-09-08 14:53:18.0327 - INFO - graphrag.index.operations.embed_text.strategies.openai - embedding 235 inputs via 235 snippets using 30 batches. max_batch_size=16, batch_max_tokens=8191
2025-09-08 14:53:18.0710 - INFO - graphrag.logger.progress - generate embeddings progress: 1/30
2025-09-08 14:53:18.0726 - INFO - graphrag.logger.progress - generate embeddings progress: 2/30
2025-09-08 14:53:18.0734 - INFO - graphrag.logger.progress - generate embeddings progress: 3/30
2025-09-08 14:53:18.0739 - INFO - graphrag.logger.progress - generate embeddings progress: 4/30
2025-09-08 14:53:18.0750 - INFO - graphrag.logger.progress - generate embeddings progress: 5/30
2025-09-08 14:53:18.0769 - INFO - graphrag.logger.progress - generate embeddings progress: 6/30
2025-09-08 14:53:18.0769 - INFO - graphrag.logger.progress - generate embeddings progress: 7/30
2025-09-08 14:53:18.0797 - INFO - graphrag.logger.progress - generate embeddings progress: 8/30
2025-09-08 14:53:18.0804 - INFO - graphrag.logger.progress - generate embeddings progress: 9/30
2025-09-08 14:53:18.0813 - INFO - graphrag.logger.progress - generate embeddings progress: 10/30
2025-09-08 14:53:18.0814 - INFO - graphrag.logger.progress - generate embeddings progress: 11/30
2025-09-08 14:53:18.0823 - INFO - graphrag.logger.progress - generate embeddings progress: 12/30
2025-09-08 14:53:18.0825 - INFO - graphrag.logger.progress - generate embeddings progress: 13/30
2025-09-08 14:53:18.0832 - INFO - graphrag.logger.progress - generate embeddings progress: 14/30
2025-09-08 14:53:18.0832 - INFO - graphrag.logger.progress - generate embeddings progress: 15/30
2025-09-08 14:53:18.0839 - INFO - graphrag.logger.progress - generate embeddings progress: 16/30
2025-09-08 14:53:18.0847 - INFO - graphrag.logger.progress - generate embeddings progress: 17/30
2025-09-08 14:53:18.0848 - INFO - graphrag.logger.progress - generate embeddings progress: 18/30
2025-09-08 14:53:18.0858 - INFO - graphrag.logger.progress - generate embeddings progress: 19/30
2025-09-08 14:53:18.0885 - INFO - graphrag.logger.progress - generate embeddings progress: 20/30
2025-09-08 14:53:18.0904 - INFO - graphrag.logger.progress - generate embeddings progress: 21/30
2025-09-08 14:53:18.0905 - INFO - graphrag.logger.progress - generate embeddings progress: 22/30
2025-09-08 14:53:18.0950 - INFO - graphrag.logger.progress - generate embeddings progress: 23/30
2025-09-08 14:53:18.0984 - INFO - graphrag.logger.progress - generate embeddings progress: 24/30
2025-09-08 14:53:18.0991 - INFO - graphrag.logger.progress - generate embeddings progress: 25/30
2025-09-08 14:53:19.0008 - INFO - graphrag.logger.progress - generate embeddings progress: 26/30
2025-09-08 14:53:19.0042 - INFO - graphrag.logger.progress - generate embeddings progress: 27/30
2025-09-08 14:53:19.0063 - INFO - graphrag.logger.progress - generate embeddings progress: 28/30
2025-09-08 14:53:19.0071 - INFO - graphrag.logger.progress - generate embeddings progress: 29/30
2025-09-08 14:53:19.0365 - INFO - graphrag.logger.progress - generate embeddings progress: 30/30
2025-09-08 14:53:19.0390 - INFO - graphrag.index.operations.embed_text.embed_text - using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
2025-09-08 14:53:19.0392 - INFO - graphrag.index.operations.embed_text.embed_text - uploading text embeddings batch 1/1 of size 500 to vector store
2025-09-08 14:53:19.0464 - INFO - graphrag.index.operations.embed_text.strategies.openai - embedding 83 inputs via 83 snippets using 13 batches. max_batch_size=16, batch_max_tokens=8191
2025-09-08 14:53:19.0821 - INFO - graphrag.logger.progress - generate embeddings progress: 1/13
2025-09-08 14:53:19.0828 - INFO - graphrag.logger.progress - generate embeddings progress: 2/13
2025-09-08 14:53:19.0835 - INFO - graphrag.logger.progress - generate embeddings progress: 3/13
2025-09-08 14:53:19.0847 - INFO - graphrag.logger.progress - generate embeddings progress: 4/13
2025-09-08 14:53:19.0848 - INFO - graphrag.logger.progress - generate embeddings progress: 5/13
2025-09-08 14:53:19.0872 - INFO - graphrag.logger.progress - generate embeddings progress: 6/13
2025-09-08 14:53:19.0873 - INFO - graphrag.logger.progress - generate embeddings progress: 7/13
2025-09-08 14:53:19.0899 - INFO - graphrag.logger.progress - generate embeddings progress: 8/13
2025-09-08 14:53:19.0916 - INFO - graphrag.logger.progress - generate embeddings progress: 9/13
2025-09-08 14:53:19.0937 - INFO - graphrag.logger.progress - generate embeddings progress: 10/13
2025-09-08 14:53:19.0993 - INFO - graphrag.logger.progress - generate embeddings progress: 11/13
2025-09-08 14:53:20.0036 - INFO - graphrag.logger.progress - generate embeddings progress: 12/13
2025-09-08 14:53:20.0042 - INFO - graphrag.logger.progress - generate embeddings progress: 13/13
2025-09-08 14:53:20.0164 - INFO - graphrag.index.workflows.generate_text_embeddings - Workflow completed: generate_text_embeddings
2025-09-08 14:53:20.0182 - INFO - graphrag.api.index - Workflow generate_text_embeddings completed successfully
2025-09-08 14:53:20.0197 - DEBUG - graphrag.api.index - {'entity.description':                                         id                                          embedding
0     ca606367-8e6b-4d04-b548-2aefcafa1ec6  [0.030280515551567078, 0.005256355740129948, 0...
1     f84cf2ff-9250-4c47-990f-d86fab33de5e  [0.04322173818945885, 0.019749585539102554, -0...
2     f0fd835e-2553-4fc4-9dd8-a6dd516f1ced  [0.031562600284814835, 0.010502537712454796, 0...
3     68cb4fb6-a965-48c1-9004-25f97d597cb6  [0.009691184386610985, 0.05455987900495529, 0....
4     30c113c2-6ce0-4b2b-aa04-428829c81e31  [0.00020151105127297342, -0.000566005997825413...
...                                    ...                                                ...
1144  5a079da2-8629-4b98-8564-dd2231859c2b  [0.06704311817884445, 0.04423581808805466, -0....
1145  805e9a3b-f902-4a00-8c62-bd30f31b0d64  [0.030215688049793243, 0.005116713233292103, 0...
1146  348b5846-a2a5-4322-ac50-0feee01dac43  [0.03233639523386955, 0.002275314647704363, 0....
1147  70d14e9f-9728-40e2-863a-a0e7237dde82  [-0.0012571641709655523, 0.0428587943315506, -...
1148  2c9651a1-c614-4e63-82f6-a3e8d6e1e90b  [0.009482517838478088, -0.004682809580117464, ...

[1149 rows x 2 columns], 'community.full_content':                                    id                                          embedding
0    903355ba0b6643f18da45c65f5feb6cb  [0.010563365183770657, 0.03660189360380173, 0....
1    8458fb09e46843fbb917ddd02cf3a6bc  [0.01679728552699089, 0.019843919202685356, 0....
2    38426d6e4c05415eba74fe4f835ca244  [0.011715480126440525, 0.057241082191467285, 0...
3    fd473d3f912a4404bb27e67bc054dcad  [0.0265662744641304, 0.037594038993120193, 0.0...
4    2aa3ff9017174d2da012dfb2f4f12e0e  [0.04423283785581589, 0.03552497923374176, 0.0...
..                                ...                                                ...
230  16c70ffb33514d5d89c3e04bb3849cc6  [-0.014622658491134644, 0.054447975009679794, ...
231  0617e8fe4adb44eab660073aed6b4b80  [0.050981663167476654, 0.031873658299446106, 0...
232  21a3d9df8f88441bab01e8288209d619  [0.0506429597735405, 0.051783330738544464, 0.0...
233  4a12e4ec29df4b9ca38c292907090e8f  [0.018208904191851616, 0.045424364507198334, 0...
234  3d98de1dfdf74ff285052449034a50c7  [0.024665232747793198, 0.04589124768972397, 0....

[235 rows x 2 columns], 'text_unit.text':                                                    id                                          embedding
0   accdca769e88d29b429be3731b96c5ceb2795667056e0f...  [0.05163923278450966, 0.05652910843491554, 0.0...
1   bac7edde4473bb43330d983443c67f1a0c8c971b98470c...  [0.006798656191676855, 0.032453253865242004, 0...
2   32bd73456930453483b1c170bf555ca0c614f897d8530e...  [0.008780913427472115, 0.049771998077631, 0.02...
3   cd7bf186a6dc62a0d87691b33552ebf17f2b95f7a54978...  [0.032943423837423325, 0.05229070782661438, 0....
4   eb7c98c0364901d44179d7cf8b255eeb20293200492db8...  [0.03986663371324539, 0.05672778934240341, 0.0...
..                                                ...                                                ...
78  cb96beb68969042181d1fc56d869f58251e2cf28667c9a...  [0.03223004937171936, 0.05843910202383995, 0.0...
79  857a7c9650ab3ab8c047946be4c4d17f4f89e696695997...  [0.02291030064225197, 0.029151644557714462, 0....
80  755ba681405a00b8d303b285b82b5b25d3a53433e81659...  [0.010158520191907883, 0.015349747613072395, 0...
81  16e9b2af109874514097d23633a85a3fbea2514b7b1257...  [0.017323046922683716, 0.056429896503686905, 0...
82  296a2e3f40ece005fad567573f5e46631e26c1a0d657dc...  [-0.009430347010493279, 0.0690484419465065, 0....

[83 rows x 2 columns]}
2025-09-08 14:53:20.0197 - INFO - graphrag.index.run.run_pipeline - Indexing pipeline complete.
2025-09-08 14:53:20.0199 - INFO - graphrag.cli.index - All workflows completed successfully.
